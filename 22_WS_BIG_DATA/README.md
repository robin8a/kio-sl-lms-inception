# References

- <https://cloud.google.com/learn/what-is-big-data?hl=es>
- <https://cloud.google.com/training/data-engineering-and-analytics?hl=es-419>
- Data Analyst Learning Path <https://www.cloudskillsboost.google/paths/18?hl=es-419&utm_campaign=evergreen&utm_medium=website&utm_source=cgc>
- Deep learning: <https://www.geeksforgeeks.org/introduction-deep-learning/>
- <https://hackmd.io/@firasj/r19X1Gwii>

## Tools

- Virtual Box
- Comunidad de DataSets <https://huggingface.co/>
- <https://archive.cloudera.com/hwx-sandbox/hdp/%20hdp-2.6.5/HDP_2.6.5_virtualbox_180626.ova/>
- <https://grouplens.org/>
- <https://jithinsisaac.github.io/posts/hdp_sandbox/>
- <https://community.cloudera.com/t5/Community-Articles/How-to-set-up-Hortonworks-Data-Cloud-HDCloud-for-AWS/ta-p/248065>

## Install

1. AWS EC2 Amazon Linux 2 (unv_pac_big_data_hadoop) (unv_pac_big_data_kp.pem)
2. <https://hackmd.io/@firasj/r19X1Gwii#Installing-Lab-Tools>
3. Docker <https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/install-docker.html>

unv_pac_user_1
unv_pac_user_2
unv_pac_user_3
unv_pac_user_4
unv_pac_user_5
unv_pac_user_6
unv_pac_user_7
unv_pac_user_8
unv_pac_user_9
unv_pac_user_10



## Map Reduce

- <https://github.com/rshah204/MapReduce-Implementation-in-PySpark/blob/master/MapReduce_PySpark.ipynb>
- Amazon_Responded_Oct05.csv <https://www.kaggle.com/datasets/sirvana/amazon-responded-tweets/data>
- <https://stackoverflow.com/questions/55240940/error-while-installing-spark-on-google-colab>



1 000 K = 3
1 000 000 M = 6
1 000 000 000 G = 9
1 000 000 000 000 T = 12
1 000 000 000 000 P = 15

4 000 000 000 000 000 E = 18

### Mastering Big Data with PySpark on Google Colab

- <https://medium.com/@siladityaghosh/mastering-big-data-with-pyspark-on-google-colab-d3c924264ceb>

- <https://colab.google/articles/bq>
